{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "parental-lithuania",
   "metadata": {},
   "source": [
    "# Evaluate completion of fMRIPrep on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stupid-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "settled-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "project_dir = \"/home/data/nbc/misc-projects/Salo_PowerReplication/\"\n",
    "\n",
    "dsets = {\n",
    "    \"dset-camcan\": [\n",
    "        \"{sub}.html\",\n",
    "        \"{sub}/func/{sub}_task-movie_echo-1_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-movie_echo-2_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-movie_echo-3_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-movie_echo-4_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-movie_echo-5_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "    ],\n",
    "    \"dset-cambridge\": [\n",
    "        \"{sub}.html\",\n",
    "        \"{sub}/func/{sub}_task-rest_echo-1_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-rest_echo-2_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-rest_echo-3_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-rest_echo-4_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "    ],\n",
    "    \"dset-dupre\": [\n",
    "        \"{sub}.html\",\n",
    "        \"{sub}/func/{sub}_task-rest_run-1_echo-1_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-rest_run-1_echo-2_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-rest_run-1_echo-3_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "    ],\n",
    "    \"dset-dalenberg\": [\n",
    "        \"{sub}.html\",\n",
    "        \"{sub}/func/{sub}_task-images_echo-1_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-images_echo-2_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-images_echo-3_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "    ],\n",
    "    \"dset-cohen\": [\n",
    "        \"{sub}.html\",\n",
    "        \"{sub}/func/{sub}_task-bilateralfingertapping_echo-1_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-bilateralfingertapping_echo-2_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-bilateralfingertapping_echo-3_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "        \"{sub}/func/{sub}_task-bilateralfingertapping_echo-4_space-scanner_desc-partialPreproc_bold.nii.gz\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "likely-mailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dset-camcan\n",
      "\tsub-CC221585\n",
      "dset-cambridge\n",
      "dset-dupre\n",
      "dset-dalenberg\n",
      "dset-cohen\n"
     ]
    }
   ],
   "source": [
    "# Find failed subjects\n",
    "for dset, target_files in dsets.items():\n",
    "    print(dset)\n",
    "    dset_dir = op.join(project_dir, dset)\n",
    "    deriv_dir = op.join(dset_dir, \"derivatives/fmriprep/\")\n",
    "    if not op.isdir(deriv_dir):\n",
    "        print(\"\\tDataset not yet processed.\")\n",
    "        continue\n",
    "\n",
    "    participants_file = op.join(dset_dir, \"participants.tsv\")\n",
    "    participants_df = pd.read_table(participants_file)\n",
    "    subject_list = participants_df[\"participant_id\"].tolist()\n",
    "    failed_subjects = []\n",
    "    for sub in subject_list:\n",
    "        tfs = [op.join(deriv_dir, temp.format(sub=sub)) for temp in target_files]\n",
    "        if not all(op.isfile(tf) for tf in tfs):\n",
    "            failed_subjects.append(sub)\n",
    "\n",
    "    if failed_subjects:\n",
    "        print(\"\\t\" + \"\\n\\t\".join(failed_subjects))\n",
    "    \n",
    "    if dset == \"dset-camcan\":\n",
    "        camcan_failed = failed_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "smooth-hospital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dset-camcan\n",
      "\tsub-CC221585.html\n",
      "\tsub-CC221585_task-movie_echo-1_space-scanner_desc-partialPreproc_bold.nii.gz\n",
      "\tsub-CC221585_task-movie_echo-2_space-scanner_desc-partialPreproc_bold.nii.gz\n",
      "\tsub-CC221585_task-movie_echo-3_space-scanner_desc-partialPreproc_bold.nii.gz\n",
      "\tsub-CC221585_task-movie_echo-4_space-scanner_desc-partialPreproc_bold.nii.gz\n",
      "\tsub-CC221585_task-movie_echo-5_space-scanner_desc-partialPreproc_bold.nii.gz\n",
      "dset-cambridge\n",
      "dset-dupre\n",
      "dset-dalenberg\n",
      "dset-cohen\n"
     ]
    }
   ],
   "source": [
    "# Find the missing files\n",
    "for dset, target_files in dsets.items():\n",
    "    print(dset)\n",
    "    dset_dir = op.join(project_dir, dset)\n",
    "    deriv_dir = op.join(dset_dir, \"derivatives/fmriprep/\")\n",
    "    if not op.isdir(deriv_dir):\n",
    "        print(\"\\tDataset not yet processed.\")\n",
    "        continue\n",
    "\n",
    "    participants_file = op.join(dset_dir, \"participants.tsv\")\n",
    "    participants_df = pd.read_table(participants_file)\n",
    "    subject_list = participants_df[\"participant_id\"].tolist()\n",
    "    failed_subjects = []\n",
    "    for sub in subject_list:\n",
    "        tfs = [op.join(deriv_dir, temp.format(sub=sub)) for temp in target_files]\n",
    "        for tf in tfs:\n",
    "            if not op.isfile(tf):\n",
    "                print(\"\\t{}\".format(op.basename(tf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-postcard",
   "metadata": {},
   "source": [
    "## Clean up the working directory for CamCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decent-canvas",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-32c500991385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise Exception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_file = op.join(project_dir, \"dset-camcan\", \"participants.tsv\")\n",
    "participants_df = pd.read_table(participants_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(camcan_failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = participants_df[\"participant_id\"].tolist()\n",
    "camcan_successful = sorted(list(set(subs) - set(camcan_failed)))\n",
    "len(camcan_successful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [str(subs.index(f) + 1) for f in camcan_failed]\n",
    "print(\",\".join(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-cycling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "\n",
    "wf_dir = \"/scratch/nbc/tsalo006/Salo_PowerReplication/dset-camcan/fmriprep-20.2.1/fmriprep_wf\"\n",
    "for sub in camcan_successful:\n",
    "    sub_name = sub.split(\"-\")[1]\n",
    "    sub_dir = f\"single_subject_{sub_name}_wf\"\n",
    "    sub_wf_dir = op.join(wf_dir, sub_dir)\n",
    "    if op.isdir(sub_wf_dir):\n",
    "        rmtree(sub_wf_dir)\n",
    "    else:\n",
    "        print(f\"Not removing {sub_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-practitioner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
